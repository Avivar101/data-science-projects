{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbf1c9eb-a98d-4e24-be41-7fbac601c44a",
   "metadata": {},
   "source": [
    "## Generating sample data\n",
    "\n",
    "We can limit the number of informative features. We can also make some features copies of any of the informative or redundant features.\n",
    "In our current case we would make sure that all our features are informative since we are going to limit ourselves to two features only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71b8aa40-3127-4b10-84a9-4d952196e90a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "719dc1a9-422a-4336-b7f0-caf96feb7dfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generating samples\n",
    "x, y = make_classification(n_samples=1000, n_features=2, n_informative=2,\n",
    "                           n_redundant=0, n_repeated=0, n_classes=2, \n",
    "                          n_clusters_per_class=2, weights=[0.98, ], class_sep=0.5,\n",
    "                          scale=1.0, shuffle=True, flip_y=0, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a436b879-fad2-4dfd-8253-5a919300d996",
   "metadata": {},
   "source": [
    "## Detecting anomalies using basic statistics\n",
    "\n",
    "Let's startby thinking about ways to detect the anomalous samples. \n",
    "\n",
    "Imaging measuring the traffic to your website every hour, which gives you the foolwing numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d9fd461-ecdd-4b1a-b67f-d04edd5e0bc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hourly_traffic = [\n",
    "    120, 123, 124, 119, 196,\n",
    "    121, 118, 117, 500, 132\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdd9f0a8-6438-41ad-83b0-93341cef6f3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae4b8670-9f6d-425d-8dae-3d2c2face808",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "5    False\n",
       "6    False\n",
       "7    False\n",
       "8     True\n",
       "9    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(hourly_traffic) > pd.Series(hourly_traffic).quantile(0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825435c3-540e-4ca4-bad4-253ad37e46ae",
   "metadata": {},
   "source": [
    "Let's put the preceeding code in form of an estimate with its `fit` and `predict` methods\n",
    "The `fit` calculate the threshold and saves it, and the `predict` method compares the new data to the saved threshold.\n",
    "Here's the code for the estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37532283-c800-49df-b55b-e9faa8664848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PercentileDetection:\n",
    "    def __init__(self, percentile=0.9):\n",
    "        self.percentile = percentile\n",
    "    def fit(self, x, y=None):\n",
    "        self.threshold = pd.Series(x).quantile(self.percentile)\n",
    "    def predict(self, x, y=None):\n",
    "        return (pd.Series(x) > self.threshold).values\n",
    "    def fit_predict(self, x, y=None):\n",
    "        self.fit(x)\n",
    "        return self.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c7cb20-ab3f-49c6-9855-7735d8c0b814",
   "metadata": {},
   "source": [
    "In the following code snippet, we use the $95th$ percentile for our estimator.\n",
    "We then put the resulting predictions alongside the priginal data into a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0185299-54b0-4a42-bcc3-f89a850a2f6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6cd31_row0_col0, #T_6cd31_row0_col1, #T_6cd31_row1_col0, #T_6cd31_row1_col1, #T_6cd31_row2_col0, #T_6cd31_row2_col1, #T_6cd31_row3_col0, #T_6cd31_row3_col1, #T_6cd31_row4_col0, #T_6cd31_row4_col1, #T_6cd31_row5_col0, #T_6cd31_row5_col1, #T_6cd31_row6_col0, #T_6cd31_row6_col1, #T_6cd31_row7_col0, #T_6cd31_row7_col1, #T_6cd31_row9_col0, #T_6cd31_row9_col1 {\n",
       "  font-weight: normal;\n",
       "}\n",
       "#T_6cd31_row8_col0, #T_6cd31_row8_col1 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6cd31\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6cd31_level0_col0\" class=\"col_heading level0 col0\" >hourly_traffic</th>\n",
       "      <th id=\"T_6cd31_level0_col1\" class=\"col_heading level0 col1\" >is_outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6cd31_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_6cd31_row0_col0\" class=\"data row0 col0\" >120</td>\n",
       "      <td id=\"T_6cd31_row0_col1\" class=\"data row0 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cd31_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_6cd31_row1_col0\" class=\"data row1 col0\" >123</td>\n",
       "      <td id=\"T_6cd31_row1_col1\" class=\"data row1 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cd31_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_6cd31_row2_col0\" class=\"data row2 col0\" >124</td>\n",
       "      <td id=\"T_6cd31_row2_col1\" class=\"data row2 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cd31_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_6cd31_row3_col0\" class=\"data row3 col0\" >119</td>\n",
       "      <td id=\"T_6cd31_row3_col1\" class=\"data row3 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cd31_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_6cd31_row4_col0\" class=\"data row4 col0\" >196</td>\n",
       "      <td id=\"T_6cd31_row4_col1\" class=\"data row4 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cd31_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_6cd31_row5_col0\" class=\"data row5 col0\" >121</td>\n",
       "      <td id=\"T_6cd31_row5_col1\" class=\"data row5 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cd31_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_6cd31_row6_col0\" class=\"data row6 col0\" >118</td>\n",
       "      <td id=\"T_6cd31_row6_col1\" class=\"data row6 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cd31_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_6cd31_row7_col0\" class=\"data row7 col0\" >117</td>\n",
       "      <td id=\"T_6cd31_row7_col1\" class=\"data row7 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cd31_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_6cd31_row8_col0\" class=\"data row8 col0\" >500</td>\n",
       "      <td id=\"T_6cd31_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cd31_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_6cd31_row9_col0\" class=\"data row9 col0\" >132</td>\n",
       "      <td id=\"T_6cd31_row9_col1\" class=\"data row9 col1\" >False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x25cb1e8b430>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlierd = PercentileDetection(percentile=0.95)\n",
    "pd.DataFrame({\n",
    "    'hourly_traffic': hourly_traffic,\n",
    "    'is_outlier': outlierd.fit_predict(hourly_traffic)\n",
    "}).style.apply(lambda row: ['font-weight: bold'] * len(row)\n",
    "              if row['is_outlier'] == True\n",
    "              else ['font-weight: normal'] * len(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d2ddb5-4fb9-4682-a3ca-06c906fa2370",
   "metadata": {},
   "source": [
    "## Using percentiles for multi-dimentional data\n",
    "\n",
    "The data we generate using `make_classification` function is multi-dimentional. We have more than one feature to check.\n",
    "\n",
    "We can check each feature seperately, i.e:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c41b8f35-db89-4735-b173-c607f7f1e243",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outlierd = PercentileDetection(percentile=0.98)\n",
    "y_pred = outlierd.fit_predict(x[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "deaf7a6c-969d-420d-8519-04b12188fcbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we can do the same for the other feature as well\n",
    "y_pred = outlierd.fit_predict(x[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c3b3ffe-3d8b-488a-b840-f07387b11f9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PercentileDetection:\n",
    "    def __init__(self, percentile=0.9):\n",
    "        self.percentile = percentile\n",
    "    def fit(self, x, y=None):\n",
    "        self.thresholds = [\n",
    "            pd.Series(x[:,i]).quantile(self.percentile) for i in range(x.shape[1])\n",
    "        ]\n",
    "    def predict(self, x, y=None):\n",
    "        return (x > self.thresholds).max(axis=1)\n",
    "    def fit_predict(self, x, y=None):\n",
    "        self.fit(x)\n",
    "        return self.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a7f947d-5a37-46f2-9f0f-53efa1351265",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we can use the tweaked estimator as follows\n",
    "outlierd = PercentileDetection(percentile=0.98)\n",
    "y_pred = outlierd.fit_predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bbdd20-b225-4628-861b-2c0184c0951f",
   "metadata": {},
   "source": [
    "We can also use the labels we ignored earlier to calculate the precision and recall of our new estimator.\n",
    "Since we care about the minority class, whose label is 1, we set `pos_label` to `1` in the following code snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44108a13-4c4c-4fad-b83d-7092a0f12b1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7258d5e-98dd-4cd7-8769-be73cd74d82a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 4.00%, Recall: 5.00% [Percentile Detection]\n"
     ]
    }
   ],
   "source": [
    "print('Precision: {:.02%}, Recall: {:.02%} [Percentile Detection]'.format(\n",
    "precision_score(y, y_pred, pos_label=1), recall_score(y, y_pred, pos_label=1),))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e970cc55-217d-4683-b34a-aedf04f54633",
   "metadata": {
    "tags": []
   },
   "source": [
    "Ouur method checks each point and sees whether it is extreme on one of the two axes.\n",
    "Despite the fct that the outliers are furthe away from the inliers, there are still inliers that share the same horizontal or vertical position of each point of the outliers. \n",
    "In other words, if you project your points onto any of the two axes, you will not be able to sepearte the outliers from the inliers anymore. So we need a way to consider the two axes at once.\n",
    "What if we find the mean point of the two axes - that is, the center of our data - and then draw an ellipse around it?. Then we can consider any point that falls outside this ellipse an outlier,\n",
    "which is what `EllipticEnvelope`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82577d00-e3dd-457f-86b4-e7f7beede405",
   "metadata": {
    "tags": []
   },
   "source": [
    "The `EllipticEnvelope` algorithm finds the enter of the data samples and then draws an Ellipsoid around that center. \n",
    "The radii of the ellipsoid in each axis are measured in the `Mahalanobis` distance.\n",
    "\n",
    "You can think of Mahalanobis distance as a `Euclidean` distance whose units are the number of standard deviations in each direction.\n",
    "After the ellipsoid is drawn, the points that faloutside it can be considered outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5eabe4b-f707-4096-83c9-29f30d66f63d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.covariance import EllipticEnvelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf373cde-949e-464d-9e0a-9e5ed24b5ffc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ee = EllipticEnvelope(random_state=0)\n",
    "y_pred = ee.fit_predict(x) == -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e625b83-8509-43b4-a4fd-5510a35c6a92",
   "metadata": {},
   "source": [
    "We can calculate the precision and the recall scores for the predictions using the exact same code from the previous section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10d53fb2-119e-4dd1-823c-dbeaa871e80e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 9.00%, Recall: 45.00% [EllipticEnvelope]\n"
     ]
    }
   ],
   "source": [
    "print('Precision: {:.02%}, Recall: {:.02%} [EllipticEnvelope]'.format(\n",
    "precision_score(y, y_pred, pos_label=1),\n",
    "recall_score(y, y_pred, pos_label=1),\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf7dec8-8722-4c17-8c81-275f04d602d3",
   "metadata": {},
   "source": [
    "## Outlier and Novelty detection using LOF\n",
    "\n",
    "LOF compares the density of a sample to the local densities of its neighbors. A sample existing in a low-density are compared to its neighbors is considered an outlier. \n",
    "\n",
    "Here's how we use `LocalOutlierFactor` for outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f1e8764-ded7-4ab3-aa4b-bfee88a3adf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "98127b81-82e6-4175-86d4-b07bac91ec07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lof = LocalOutlierFactor(n_neighbors=50)\n",
    "y_pred = lof.fit_predict(x) == -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b353f0e8-7ac8-49c8-ad00-01a1c7b0d379",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 26.00%, Recall: 65.00% [LOC]\n"
     ]
    }
   ],
   "source": [
    "print('Precision: {:.02%}, Recall: {:.02%} [LOC]'.format(\n",
    "precision_score(y, y_pred, pos_label=1),\n",
    "recall_score(y, y_pred, pos_label=1),\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4195f33a-ea13-4ff2-b533-aeb012de3a62",
   "metadata": {},
   "source": [
    "Outlier detection algorithms not only give us binary predictions, but can also tell us how confident they are that a sample is an outlier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab710bf8-7d35-498d-bbd2-0a40d5c9d159",
   "metadata": {},
   "source": [
    "A sample is more likely to be an outlier if the score is closer to `-1`. So, we can use this score and set its bottom 1%, 2%, or 10% values as outliers, and consider the rest inliers.\n",
    "\n",
    "Hers is a omparison for the different performance metrics at each of the aforementioned thresholds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9287da4d-6f1d-4103-a911-dbc1d494b71c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOF: Precision: 80.00%, Recall: 40.00% [Quantile=1%]\n",
      "LOF: Precision: 50.00%, Recall: 50.00% [Quantile=2%]\n",
      "LOF: Precision: 14.00%, Recall: 70.00% [Quantile=10%]\n"
     ]
    }
   ],
   "source": [
    "lof.fit(x)\n",
    "\n",
    "for quantile in [0.01, 0.02, 0.1]:\n",
    "    y_pred = lof.negative_outlier_factor_ < np.quantile(\n",
    "    lof.negative_outlier_factor_, quantile)\n",
    "    \n",
    "    print('LOF: Precision: {:.02%}, Recall: {:.02%} [Quantile={:.0%}]'.format(\n",
    "    precision_score(y, y_pred, pos_label=1),\n",
    "    recall_score(y, y_pred, pos_label=1),\n",
    "    quantile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "124e27b1-2cd8-4ac7-bce2-c029b96b4fad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cc2643-8c1f-4d49-aa3e-a246ab734c06",
   "metadata": {},
   "source": [
    "## Novelty detection using LOF\n",
    "\n",
    "Aside from its use for outlier detection, the LOF algorithm can also be used for novelty detection\n",
    "\n",
    "When used for outlier detection, the algorithm has to be fitted on the dataset with both its inliers and outliers.\n",
    "\n",
    "In the case of Novelyt Detection, we are expected to fit the algorithm on inliers only and then predict the contaminated dataset later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "506b5bac-5c1d-4699-962e-88cd3f422396",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_inliers = x[y==0]\n",
    "\n",
    "lof_ = LocalOutlierFactor(n_neighbors=50, novelty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b77de1c1-a641-47e9-aae2-9cec1d7a0735",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lof_.fit(x_inliers)\n",
    "y_pred = lof_.predict(x) == -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "607ff317-04e0-4941-a3ea-29d6e8d5571c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 26.53%, Recall: 65.00% [LOC Novelty Detector]\n"
     ]
    }
   ],
   "source": [
    "print('Precision: {:.02%}, Recall: {:.02%} [LOC Novelty Detector]'.format(\n",
    "precision_score(y, y_pred, pos_label=1),\n",
    "recall_score(y, y_pred, pos_label=1),\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84261f9-fd08-4dff-bed8-249c0417ef47",
   "metadata": {},
   "source": [
    "## Detecting outliers using isolation forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "df24a795-eb17-4240-92c3-b7424b5e2ce3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a4d1060e-087c-4472-803a-12af384203ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iforest = IsolationForest(n_estimators=200, n_jobs=-1, random_state=10)\n",
    "y_pred = iforest.fit_predict(x) == -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "960c599c-f8ec-4624-9006-be2410beaecd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 6.45%, Recall: 60.00% [Isolation Forest]\n"
     ]
    }
   ],
   "source": [
    "print('Precision: {:.02%}, Recall: {:.02%} [Isolation Forest]'.format(\n",
    "precision_score(y, y_pred, pos_label=1),\n",
    "recall_score(y, y_pred, pos_label=1),\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe0051c-1703-432e-a856-d1bd3ad38781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml_dev]",
   "language": "python",
   "name": "conda-env-ml_dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
